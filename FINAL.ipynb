{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Studenti:\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Mihai Lacusteanu\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Alexandru-Florian Ion \n",
    "#### Profesor: \n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Victor-Emil Neagoe\n",
    "\n",
    "\n",
    "Baza de date: https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Imagini si clasele lor:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](all3.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\ktfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\ktfgpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 309,290\n",
      "Trainable params: 308,394\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    " \n",
    "    \n",
    "batch_size = 300\n",
    "nr_epoci = 50\n",
    "\n",
    "\n",
    "def rata_de_invatare_controlata(epoch):\n",
    "    lrate = 0.005\n",
    "    if epoch > 10:\n",
    "        lrate = 0.001\n",
    "    if epoch > 20:\n",
    "        lrate = 0.0001\n",
    "    if epoch > 30:\n",
    "        lrate = 0.00005\n",
    "    if epoch > 40:\n",
    "        lrate = 0.00001\n",
    "    return lrate\n",
    " \n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    " \n",
    "#z-score\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)\n",
    " \n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train,num_classes)\n",
    "y_test = np_utils.to_categorical(y_test,num_classes)\n",
    " \n",
    "weight_decay = 1e-4\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    " \n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    " \n",
    "model.summary()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\ktfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "166/166 [==============================] - 21s 126ms/step - loss: 2.9032 - acc: 0.2955 - val_loss: 1.7766 - val_acc: 0.4087\n",
      "Epoch 2/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 1.7534 - acc: 0.4409 - val_loss: 1.6600 - val_acc: 0.4354\n",
      "Epoch 3/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 1.6028 - acc: 0.4975 - val_loss: 1.4540 - val_acc: 0.5047\n",
      "Epoch 4/50\n",
      "166/166 [==============================] - 18s 106ms/step - loss: 1.5502 - acc: 0.5245 - val_loss: 2.2082 - val_acc: 0.3998\n",
      "Epoch 5/50\n",
      "166/166 [==============================] - 18s 106ms/step - loss: 1.4635 - acc: 0.5515 - val_loss: 1.4151 - val_acc: 0.5616\n",
      "Epoch 6/50\n",
      "166/166 [==============================] - 18s 106ms/step - loss: 1.3688 - acc: 0.5796 - val_loss: 1.1407 - val_acc: 0.6516\n",
      "Epoch 7/50\n",
      "166/166 [==============================] - 18s 109ms/step - loss: 1.3125 - acc: 0.6062 - val_loss: 1.5217 - val_acc: 0.5269\n",
      "Epoch 8/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 1.2671 - acc: 0.6241 - val_loss: 1.1976 - val_acc: 0.6475\n",
      "Epoch 9/50\n",
      "166/166 [==============================] - 18s 106ms/step - loss: 1.2078 - acc: 0.6452 - val_loss: 1.4634 - val_acc: 0.5873\n",
      "Epoch 10/50\n",
      "166/166 [==============================] - 18s 108ms/step - loss: 1.1703 - acc: 0.6631 - val_loss: 1.3479 - val_acc: 0.6177\n",
      "Epoch 11/50\n",
      "166/166 [==============================] - 18s 107ms/step - loss: 1.1465 - acc: 0.6781 - val_loss: 1.0219 - val_acc: 0.7124\n",
      "Epoch 12/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.9943 - acc: 0.7208 - val_loss: 0.9346 - val_acc: 0.7360\n",
      "Epoch 13/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.9379 - acc: 0.7376 - val_loss: 0.9423 - val_acc: 0.7356\n",
      "Epoch 14/50\n",
      "166/166 [==============================] - 18s 106ms/step - loss: 0.9141 - acc: 0.7401 - val_loss: 0.9437 - val_acc: 0.7285\n",
      "Epoch 15/50\n",
      "166/166 [==============================] - 18s 107ms/step - loss: 0.8794 - acc: 0.7482 - val_loss: 0.8224 - val_acc: 0.7627\n",
      "Epoch 16/50\n",
      "166/166 [==============================] - 17s 104ms/step - loss: 0.8497 - acc: 0.7558 - val_loss: 0.8181 - val_acc: 0.7603\n",
      "Epoch 17/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.8304 - acc: 0.7583 - val_loss: 0.7805 - val_acc: 0.7752\n",
      "Epoch 18/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.7995 - acc: 0.7647 - val_loss: 0.8053 - val_acc: 0.7699\n",
      "Epoch 19/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.7846 - acc: 0.7703 - val_loss: 0.7150 - val_acc: 0.7891\n",
      "Epoch 20/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.7655 - acc: 0.7746 - val_loss: 0.7667 - val_acc: 0.7792\n",
      "Epoch 21/50\n",
      "166/166 [==============================] - 18s 106ms/step - loss: 0.7519 - acc: 0.7786 - val_loss: 0.7502 - val_acc: 0.7832\n",
      "Epoch 22/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.7203 - acc: 0.7910 - val_loss: 0.6943 - val_acc: 0.8006\n",
      "Epoch 23/50\n",
      "166/166 [==============================] - 17s 104ms/step - loss: 0.7106 - acc: 0.7934 - val_loss: 0.6842 - val_acc: 0.8055\n",
      "Epoch 24/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.7026 - acc: 0.7961 - val_loss: 0.6869 - val_acc: 0.8069\n",
      "Epoch 25/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.6985 - acc: 0.7954 - val_loss: 0.6874 - val_acc: 0.8051\n",
      "Epoch 26/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.6950 - acc: 0.7992 - val_loss: 0.6881 - val_acc: 0.8059\n",
      "Epoch 27/50\n",
      "166/166 [==============================] - 17s 104ms/step - loss: 0.6940 - acc: 0.7984 - val_loss: 0.6811 - val_acc: 0.8068\n",
      "Epoch 28/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.6947 - acc: 0.7970 - val_loss: 0.6771 - val_acc: 0.8073\n",
      "Epoch 29/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.6866 - acc: 0.7993 - val_loss: 0.6847 - val_acc: 0.8050\n",
      "Epoch 30/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.6859 - acc: 0.8012 - val_loss: 0.6670 - val_acc: 0.8109\n",
      "Epoch 31/50\n",
      "166/166 [==============================] - 18s 106ms/step - loss: 0.6800 - acc: 0.8016 - val_loss: 0.6612 - val_acc: 0.8145\n",
      "Epoch 32/50\n",
      "166/166 [==============================] - 18s 106ms/step - loss: 0.6781 - acc: 0.8032 - val_loss: 0.6612 - val_acc: 0.8154\n",
      "Epoch 33/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.6728 - acc: 0.8024 - val_loss: 0.6584 - val_acc: 0.8153\n",
      "Epoch 34/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.6682 - acc: 0.8049 - val_loss: 0.6657 - val_acc: 0.8132\n",
      "Epoch 35/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.6745 - acc: 0.8029 - val_loss: 0.6586 - val_acc: 0.8164\n",
      "Epoch 36/50\n",
      "166/166 [==============================] - 18s 106ms/step - loss: 0.6682 - acc: 0.8063 - val_loss: 0.6512 - val_acc: 0.8192\n",
      "Epoch 37/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.6659 - acc: 0.8076 - val_loss: 0.6593 - val_acc: 0.8162\n",
      "Epoch 38/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.6635 - acc: 0.8081 - val_loss: 0.6616 - val_acc: 0.8153\n",
      "Epoch 39/50\n",
      "166/166 [==============================] - 18s 106ms/step - loss: 0.6683 - acc: 0.8070 - val_loss: 0.6552 - val_acc: 0.8154\n",
      "Epoch 40/50\n",
      "166/166 [==============================] - 18s 105ms/step - loss: 0.6644 - acc: 0.8072 - val_loss: 0.6573 - val_acc: 0.8156\n",
      "Epoch 41/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.6639 - acc: 0.8082 - val_loss: 0.6589 - val_acc: 0.8171\n",
      "Epoch 42/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.6566 - acc: 0.8076 - val_loss: 0.6560 - val_acc: 0.8184\n",
      "Epoch 43/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.6556 - acc: 0.8102 - val_loss: 0.6577 - val_acc: 0.8172\n",
      "Epoch 44/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.6579 - acc: 0.8069 - val_loss: 0.6561 - val_acc: 0.8177\n",
      "Epoch 45/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.6583 - acc: 0.8107 - val_loss: 0.6553 - val_acc: 0.8177\n",
      "Epoch 46/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.6574 - acc: 0.8108 - val_loss: 0.6541 - val_acc: 0.8180\n",
      "Epoch 47/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.6592 - acc: 0.8083 - val_loss: 0.6546 - val_acc: 0.8180\n",
      "Epoch 48/50\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.6677 - acc: 0.8042 - val_loss: 0.6541 - val_acc: 0.8171\n",
      "Epoch 49/50\n",
      "166/166 [==============================] - 18s 106ms/step - loss: 0.6665 - acc: 0.8083 - val_loss: 0.6555 - val_acc: 0.8175\n",
      "Epoch 50/50\n",
      "166/166 [==============================] - 18s 106ms/step - loss: 0.6594 - acc: 0.8088 - val_loss: 0.6531 - val_acc: 0.8180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24f5a74b518>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#augmentare imagini\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    )\n",
    "datagen.fit(x_train)\n",
    " \n",
    "#antrenare\n",
    "\n",
    " \n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=nr_epoci,\\\n",
    "                    verbose=1,validation_data=(x_test,y_test),callbacks=[LearningRateScheduler(rata_de_invatare_controlata)])\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvare model\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%d%m%Y_%H%M%S\")\n",
    "model_name = 'model_' + date_time\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(model_name + '.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(model_name + '.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 67us/step\n",
      "\n",
      "Acuratete: 81.800 Functie Cost: 0.653\n"
     ]
    }
   ],
   "source": [
    "#testare\n",
    "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
    "print('\\nAcuratete: %.3f Functie Cost: %.3f' % (scores[1]*100,scores[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "y_pred = (predictions > 0.5)\n",
    "matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[872,  18,  14,   5,   7,   1,   7,   5,  36,  35],\n",
       "       [ 15, 922,   0,   0,   0,   0,   2,   0,   6,  55],\n",
       "       [185,   3, 612,   9,  54,  13,  97,  12,   3,  12],\n",
       "       [218,   8,  18, 498,  41,  64, 100,  18,  14,  21],\n",
       "       [111,   1,  15,   9, 757,   1,  73,  30,   2,   1],\n",
       "       [201,   2,   8,  69,  29, 599,  38,  45,   0,   9],\n",
       "       [ 47,   0,   5,   9,   4,   0, 932,   2,   1,   0],\n",
       "       [ 76,   1,   3,   4,  23,   5,  13, 864,   1,  10],\n",
       "       [ 67,  13,   0,   1,   0,   0,   5,   1, 883,  30],\n",
       "       [ 29,  31,   1,   1,   0,   0,   1,   1,   5, 931]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observatii:\n",
    "Setul de date contine imagini in care obiectele sunt de marimi si inclinatii diferite asa ca augumentarea imaginilor imbunatateste acuratetea cu un procent de 10%\n",
    "Imaginile sunt destul de complexe ceea ce implica o structura cu multe straturi si multi neuroni pe fiecare strat, ceea ce la randul ei implica un set de date mai mare decat cel pe care il avem la dispozitie \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
